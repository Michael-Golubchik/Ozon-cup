{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cba6b9-cde7-40de-8fe7-c9aebab3808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'start.ipynb'\n",
    "from baseline import train_bert, check_bert\n",
    "import wandb\n",
    "wandb.login(key=\"68be83ff5b81233c60ffad40f6327a3700797a16\")\n",
    "#check_bert()\n",
    "train_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba783590-4d24-47cf-afc4-9c4f2f22be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from related_split import related_split_train_valid\n",
    "\n",
    "# Для примера создадим DataFrame\n",
    "data = {\n",
    "    'variantid1': np.random.randint(1, 100, 30),\n",
    "    'variantid2': np.random.randint(1, 100, 30)\n",
    "}\n",
    "\n",
    "train_data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b0ec8-017d-4fb0-8604-be6aa5890874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, valid_split = related_split_train_valid(train_data)\n",
    "train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb3838-787c-450f-84e4-3df0f1fa6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e491f-c50b-4144-bcd3-f63f9abb6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c0f10-8be1-436f-9437-7a825c605323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "train_idx = joblib.load('./data/train_idx.pkl')\n",
    "val_idx = joblib.load('./data/val_idx.pkl')\n",
    "train_data_all = joblib.load('./data/train_data_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b4f0d-c98c-4f42-9d73-1c4f9ed46b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_all.shape)\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7c864-31bc-4e02-9ebb-dcd0d1df0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "val_data = joblib.load('./data/val_data.pkl')\n",
    "train_data = joblib.load('./data/train_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227a281-c590-446b-beeb-f00889bd7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd6065-2211-4866-8ba5-35f1ab7313e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b56e42-e1be-428a-8b7b-622ed40d4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Предположим, что val_data содержит ваши эмбеддинги\n",
    "# Получаем эмбеддинги\n",
    "embedding_1 = val_data.loc[2]['name_bert_1']\n",
    "embedding_2 = val_data.loc[2]['name_bert_2']\n",
    "\n",
    "# Преобразуем эмбеддинги в двумерные массивы (требуется для cosine_similarity)\n",
    "embedding_1 = embedding_1.reshape(1, -1)\n",
    "embedding_2 = embedding_2.reshape(1, -1)\n",
    "\n",
    "# Вычисляем косинусное сходство\n",
    "similarity = cosine_similarity(embedding_1, embedding_2)\n",
    "\n",
    "print(f\"Косинусное сходство: {similarity[0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70896f-7f27-454c-9785-dfaefec7fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(val_data.loc[0]['name_bert_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111ee72-97a1-40ba-856f-c3ec0a4481f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(train_data_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cf1c2-3aa2-4f84-9cf6-de6d3fdeae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка пересекающихся индексов\n",
    "intersecting_indices = val_data.index.intersection(train_data.index)\n",
    "if not intersecting_indices.empty:\n",
    "    print(\"Есть пересекающиеся индексы между val_data и train_data:\", intersecting_indices)\n",
    "else:\n",
    "    print(\"Нет пересекающихся индексов между val_data и train_data.\")\n",
    "\n",
    "# Проверка одинаковых идентификаторов в столбцах variantid1\n",
    "intersecting_variantid1 = set(val_data['variantid1']).intersection(set(train_data['variantid1']))\n",
    "intersecting_variantid12 = set(val_data['variantid1']).intersection(set(train_data['variantid2']))\n",
    "if intersecting_variantid1 or intersecting_variantid12:\n",
    "    print(\"Есть пересекающиеся идентификаторы в столбце variantid1:\", intersecting_variantid1)\n",
    "else:\n",
    "    print(\"Нет пересекающихся идентификаторов в столбце variantid1.\")\n",
    "\n",
    "# Проверка одинаковых идентификаторов в столбцах variantid2\n",
    "intersecting_variantid2 = set(val_data['variantid2']).intersection(set(train_data['variantid2']))\n",
    "intersecting_variantid21 = set(val_data['variantid2']).intersection(set(train_data['variantid1']))\n",
    "if intersecting_variantid2 or intersecting_variantid21:\n",
    "    print(\"Есть пересекающиеся идентификаторы в столбце variantid2:\", intersecting_variantid2)\n",
    "else:\n",
    "    print(\"Нет пересекающихся идентификаторов в столбце variantid2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14156f-486d-4e48-9c00-087ab1b8d996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08cbcd1-f8bd-4652-8ac9-8b18d67b77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f7e09-c90d-4d1a-8eed-4b64eb90ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Два текста для сравнения\n",
    "#text1 = \"Пример первого текста для анализа сходства.\"\n",
    "#text2 = \"Этот текст является вторым примером для определения похожести.\"\n",
    "text1 = \"112\"\n",
    "text2 = \"223\"\n",
    "\n",
    "\n",
    "\n",
    "# Создание экземпляра TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Преобразование текстов в TF-IDF векторы\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
    "\n",
    "# Вычисление косинусного сходства между двумя текстовыми векторами\n",
    "similarity_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([text3, text4])\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "print(f\"Cosine Similarity between texts: {similarity_score[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369218c-9a62-4eeb-b705-f9584dc2acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba595a6-97c7-44f8-beda-52e1fd37b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = joblib.load('./data/val_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefd115-ddec-44e0-8ebd-8143566d181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd1ae1-2a26-4300-9a1c-b88255abe5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.loc[4]['main_pic_embeddings_resnet_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e8c1b-993e-41ba-b2d7-1d43fba2e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.loc[4]['pic_embeddings_resnet_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b299eb3-db05-4a8d-a399-3a3f57e739cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_data.loc[3]['pic_embeddings_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834ac96-25d8-4a40-8056-5badb1ba2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embedding1 = np.mean(val_data.loc[3]['pic_embeddings_1'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa10408-d9d2-414f-b332-ec8c3e1935e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embedding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a5645-44e7-4a8b-9703-e1af16079f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Функция для объединения всех вложенных numpy.ndarray в один массив с сохранением структуры\n",
    "def combine_embeddings(row):\n",
    "    # Извлечение массивов из колонок\n",
    "    embed1 = row['main_pic_embeddings_resnet_v1']\n",
    "    embed2 = row['pic_embeddings_resnet_v1']\n",
    "    \n",
    "    # Создаем пустой список для хранения всех вложенных массивов\n",
    "    combined_embeds = []\n",
    "    \n",
    "    # Если поле не пустое, добавляем его вложенные массивы в общий список\n",
    "    if isinstance(embed1, np.ndarray):\n",
    "        combined_embeds.extend(embed1)  # Добавляем все элементы из embed1\n",
    "    if isinstance(embed2, np.ndarray):\n",
    "        combined_embeds.extend(embed2)  # Добавляем все элементы из embed2\n",
    "    \n",
    "    # Преобразуем список обратно в numpy массив\n",
    "    return np.array(combined_embeds)\n",
    "\n",
    "# Применение функции к DataFrame и обновление колонки main_pic_embeddings_resnet_v1\n",
    "val_data['main_pic_all'] = val_data.apply(combine_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7d9bf-4625-4bd6-9fd7-aa4ce729c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "#text_and_bert = pd.read_parquet('./data/train/text_and_bert.parquet')\n",
    "attributes = pd.read_parquet('./data/train/attributes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2dfb7b-189c-41b0-bba2-6e6358f96227",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f67926-aead-4d35-a732-f7494130bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.loc[0]['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c439a3-091d-40af-a12c-cd3fdb1617d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.loc[0]['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a1522-ff29-4817-8740-24184198168f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Создание словарей для хранения уникальных значений по каждой категории\n",
    "unique_categories = {\"1\": set(), \"2\": set(), \"3\": set(), \"4\": set()}\n",
    "\n",
    "# Проход по всем строкам DataFrame\n",
    "for index, row in attributes.iterrows():\n",
    "    categories_json = row['categories']\n",
    "    categories_dict = json.loads(categories_json)\n",
    "    \n",
    "    # Добавление уникальных значений для каждой категории в соответствующее множество\n",
    "    for key in unique_categories.keys():\n",
    "        category_name = categories_dict.get(key)\n",
    "        if category_name:  # Если значение существует, добавляем в множество\n",
    "            unique_categories[key].add(category_name)\n",
    "\n",
    "# Печать количества уникальных значений и сами значения для каждой категории\n",
    "for key, values in unique_categories.items():\n",
    "    print(f\"Количество уникальных названий в категории '{key}': {len(values)}\")\n",
    "    print(f\"Все уникальные названия в категории '{key}': {values}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d95783-b308-4082-9fbd-b0742cef3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    #get_cosine_similarity(embed1,embed2)\n",
    "    d= 1- cosine(embed1,embed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205288a0-a1a7-4203-8375-ea5c87e1fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU times: total: 2.5 s\n",
    "Wall time: 3.79 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e493ca6-ad50-4565-a921-681659ce166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Пример функции, которая принимает строку и дополнительные аргументы\n",
    "def make_features_for_row(row, arg1, arg2):\n",
    "    # Ваша логика создания признаков\n",
    "    feature = row['column1'] * arg1 + row['column2'] * arg2\n",
    "    return feature\n",
    "\n",
    "# Создание примерного DataFrame\n",
    "data = {'column1': [1, 2, 3], 'column2': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Применение функции с передачей дополнительных аргументов\n",
    "df['features'] = df.apply(make_features_for_row, axis=1, args=(10, 20))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f6990-daf0-4e63-9152-c89b1d733446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "#model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "# model.cuda()  # uncomment it if you have a GPU\n",
    "\n",
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    #embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "print('***',embed_bert_cls('привет мир', model, tokenizer).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a4b4f-21cb-4a0d-8c15-0adaec021072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Загрузка модели и токенизатора BERT\n",
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "#model_name = 'cointegrated/rubert-tiny'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)  # Используйте BertModel, а не BertForSequenceClassification\n",
    "#model = torch.load ('bert.pkl')\n",
    "\n",
    "# Функция для создания эмбеддингов BERT\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Используйте last_hidden_state для извлечения эмбеддингов\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Пример использования\n",
    "# for i in range(300):\n",
    "#     text = \"Пример 1\"\n",
    "#     embedding = get_bert_embedding(text)\n",
    "#print(embedding)\n",
    "embed1 = get_bert_embedding('Полотенце детское')\n",
    "#embed2 = get_bert_embedding('Полотенцесушитель')\n",
    "embed2 = get_bert_embedding('Парфюмерная вода')\n",
    "dist = 1-cosine(embed1, embed2)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148841ec-3bb3-4812-9475-02dadd4c3685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Загрузка модели и токенизатора BERT\n",
    "#model_name = 'DeepPavlov/rubert-base-cased'\n",
    "#model_name = 'cointegrated/rubert-tiny'\n",
    "model_name = 'cointegrated/rubert-tiny2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)  # Используйте BertModel, а не BertForSequenceClassification\n",
    "\n",
    "# Функция для создания эмбеддингов BERT\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Используйте last_hidden_state для извлечения эмбеддингов\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Пример использования\n",
    "# for i in range(300):\n",
    "#     text = \"Пример 1\"\n",
    "#     embedding = get_bert_embedding(text)\n",
    "embedding = get_bert_embedding('Набор для рукоделия, творчества')\n",
    "# print(embedding)\n",
    "#embed1 = get_bert_embedding('Полотенце детское')\n",
    "embed1 = get_bert_embedding('100')\n",
    "#embed2 = get_bert_embedding('Полотенцесушитель')\n",
    "#embed2 = get_bert_embedding('Парфюмерная вода')\n",
    "\n",
    "dist = 1-cosine(embed1, embed2)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52ec8e-63f2-43e2-b5e2-ac715f399c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "val_data = joblib.load('./data/val_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f871843-926a-4fe4-8b38-36f78b258ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape\n",
    "val_data_head = val_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ecaca-e9e9-4c53-9d8b-bea901916574",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bbfa6-3051-41b6-96d3-21e82ce26f7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_data_head.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc91d6-da3c-4054-a426-b4341a7d9236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Загрузка модели и токенизатора BERT\n",
    "# model_name = 'bert-base-uncased'\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "model_name = 'cointegrated/rubert-tiny2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name) \n",
    "\n",
    "# Функция для создания эмбеддингов BERT\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "# Создание множества для хранения всех уникальных значений категорий\n",
    "unique_values = set()\n",
    "\n",
    "# Проход по всем строкам DataFrame и сбор уникальных значений\n",
    "for index, row in val_data_head.iterrows():\n",
    "    # Добавляем все значения категорий в множество уникальных значений\n",
    "    unique_values.update(row['categories_1'].values(),\n",
    "                        row['categories_2'].values())\n",
    "\n",
    "# Создание словаря эмбеддингов категорий, где ключи - уникальные значения, а значения - их эмбеддинги BERT\n",
    "categories_embeddings_dict = {value: get_bert_embedding(value) for value in unique_values}\n",
    "\n",
    "# Пример вывода\n",
    "for key, embedding in embeddings_dict.items():\n",
    "    print(f\"Ключ: {key}\")\n",
    "    print(f\"Эмбеддинг: {embedding[:5]}...\")  # Выводим первые 5 значений эмбеддинга для краткости\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa89cf8-5df6-4b71-83bf-acf7cd59540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 25\n",
    "print(val_data.loc[i]['categories_1'])\n",
    "print(val_data.loc[i]['categories_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12234e48-7f31-440f-a69f-4132bf712c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_head.loc[0]['categories_1']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e3e9fb-aecc-408f-80dd-12df6fdff318",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_head.loc[0]['categories_1']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb1b93-ef68-4cdf-87e3-5a77cc34f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680eb76a-d6a2-44ed-b033-1fafa9232015",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_distance['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c68ea3-f4f3-4791-a6c3-4975bb954614",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_head.loc[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af56ca-3aed-4f78-bedf-ff5953a42851",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.loc[25]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984bc82-6f78-41c5-87ad-e94124bde74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 25\n",
    "print(val_data.loc[0:10]['characteristic_attributes_mapping_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17957209-3d92-4ee2-b345-ff0cb7094804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Предположим, val_data уже загружен как DataFrame\n",
    "\n",
    "# Создание словаря для хранения частоты встречаемости ключей\n",
    "key_frequency = defaultdict(int)\n",
    "\n",
    "# Проход по всем строкам в val_data и подсчёт ключей\n",
    "for i, row in val_data.iterrows():\n",
    "    # Учитываем ключи из первой колонки\n",
    "    if pd.notnull(row['characteristic_attributes_mapping_1']):\n",
    "        for key in row['characteristic_attributes_mapping_1'].keys():\n",
    "            key_frequency[key] += 1\n",
    "    \n",
    "    # Учитываем ключи из второй колонки\n",
    "    if pd.notnull(row['characteristic_attributes_mapping_2']):\n",
    "        for key in row['characteristic_attributes_mapping_2'].keys():\n",
    "            key_frequency[key] += 1\n",
    "\n",
    "# Сортировка ключей по частоте встречаемости в порядке убывания\n",
    "sorted_key_frequency = sorted(key_frequency.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Количество уникальных ключей: {len(sorted_key_frequency)}\")\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Ключи отсортированы по убыванию встречаемости:\")\n",
    "# for key, freq in sorted_key_frequency:\n",
    "#     print(f\"{key}: {freq} раз(а)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e437ae-c6b5-4a9d-abea-c5eb85fd3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3186c3c-0464-4667-905b-78cb595b33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e1389-fea9-40cc-b610-f2bfed57591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[['characteristic_attributes_mapping_1','characteristic_attributes_mapping_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562217a2-afcf-4817-a074-f60d6f6a61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "val_data = joblib.load('./data/result_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3aa1e-27cf-4df7-879b-861deef63368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Предположим, val_data уже загружен как DataFrame\n",
    "\n",
    "# Извлечение нужных колонок\n",
    "# columns_to_export = val_data[['characteristic_attributes_mapping_1', 'characteristic_attributes_mapping_2', 'name_1', 'name_2', 'target', 'y_pred', 'y_pred_prob', 'features']]\n",
    "\n",
    "# Запись в текстовый файл\n",
    "with open('output.txt', 'w', encoding='utf-8') as file:\n",
    "    for index, row in val_data.iterrows():\n",
    "        file.write(f\"Row: {index}:, Target: {row['target']}, y_pred: {row['y_pred']}, y_pred_prob: {row['y_pred_prob']}:\")\n",
    "        if row['target'] == row['y_pred']:\n",
    "            file.write(f\"  Good\\n\")\n",
    "        else:\n",
    "            file.write(f\"  Mistake!!!\\n\")\n",
    "        file.write(f\"Name_1: {row['name_1']}:\\n\")\n",
    "        # Запись ключей и значений из characteristic_attributes_mapping_1\n",
    "        if pd.notnull(row['characteristic_attributes_mapping_1']):\n",
    "            file.write(\"characteristic_attributes_mapping_1:\\n\")\n",
    "            for key, value in row['characteristic_attributes_mapping_1'].items():\n",
    "                file.write(f\"  * {key}: {', '.join(value)}\\n\")\n",
    "        \n",
    "        file.write(f\"+++++:\\n\")\n",
    "        file.write(f\"Name_2: {row['name_2']}:\\n\")\n",
    "        # Запись ключей и значений из characteristic_attributes_mapping_2\n",
    "        if pd.notnull(row['characteristic_attributes_mapping_2']):\n",
    "            file.write(\"characteristic_attributes_mapping_2:\\n\")\n",
    "            for key, value in row['characteristic_attributes_mapping_2'].items():\n",
    "                file.write(f\"  * {key}: {', '.join(value)}\\n\")\n",
    "\n",
    "        feature_names = [\n",
    "            \n",
    "        ]\n",
    "        for i, feature in enumerate(row['features']):\n",
    "        \n",
    "        file.write(\"***********************************************\\n\")  # Добавляем пустую строку между записями\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af9789-b0fc-4509-a7dd-4a21f73b2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pattern_attributes.txt', 'r', encoding='utf-8') as file:\n",
    "    exact_attributes = [line.strip() for line in file]\n",
    "print('Начальная длина списка атрибутов:', len(exact_attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f24ca-66ea-45c9-85f1-41120a663241",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.loc[13]['categories_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947b742-a964-4be2-ad48-c45400da74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.loc[13]['categories_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4127bd-f817-45e8-af98-6f64454d281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "text_and_bert = pd.read_parquet('./data/train/text_and_bert.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc950c6-c941-4aa5-ac5a-60bad1c28fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_and_bert.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985fc8d-4bce-41ae-90e6-4dd6f92e980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d301050-4f3f-4930-8597-514e2c718f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращает атрибуты в виде словаря переделанные в строку строку \n",
    "def get_characteristic_attributes_mapping_string(characteristic_attributes_mapping):\n",
    "    ret_str = ''\n",
    "    for key, value in characteristic_attributes_mapping.items():\n",
    "        ret_str += f\"{key}: {', '.join(value)} \"\n",
    "    return ret_str\n",
    "\n",
    "ret1 = get_characteristic_attributes_mapping_string(val_data.loc[3]['characteristic_attributes_mapping_1'])\n",
    "ret2 = get_characteristic_attributes_mapping_string(val_data.loc[3]['characteristic_attributes_mapping_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f158c9f-c6fb-460a-a2f7-7b28cfa78ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ret1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a653c-e7e6-4fae-8ff3-4dd01bd274af",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(ret1 != ret2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142616c-d250-4181-8762-82b2d423f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.loc[0]['characteristic_attributes_mapping_1'] == val_data.loc[0]['characteristic_attributes_mapping_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459a9d4-3892-4eaa-8c79-57d9aa06d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_data.loc[13]['characteristic_attributes_mapping_1']['Артикул'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09979c07-5d36-4d5b-82a1-947fde7e730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_data.loc[1]['characteristic_attributes_mapping_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701acc2-bc2e-4047-9515-530a4eaf9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "ret.extend([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a7046-a24c-4c84-aa9e-d7d24f929c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810910a7-78d5-4044-abd6-9d8fa156f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'a': 1, 'b': 2, 'c': 3}\n",
    "dict2 = {'a': 1, 'b': 20, 'd': 4}\n",
    "\n",
    "# Полное сравнение\n",
    "print(dict1 == dict2)  # False\n",
    "\n",
    "# Сравнение ключей\n",
    "print(dict1.keys() == dict2.keys())  # False\n",
    "\n",
    "# Вывод различий\n",
    "only_in_dict1 = dict1.keys() - dict2.keys()  # {'c'}\n",
    "only_in_dict2 = dict2.keys() - dict1.keys()  # {'d'}\n",
    "differing_values = {key: (dict1[key], dict2[key]) for key in dict1.keys() & dict2.keys() if dict1[key] != dict2[key]}  # {'b': (2, 20)}\n",
    "\n",
    "print(f\"Ключи только в dict1: {only_in_dict1}\")\n",
    "print(f\"Ключи только в dict2: {only_in_dict2}\")\n",
    "print(f\"Различия в значениях: {differing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b4d9a-de70-4b8e-a81e-753da11e08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "float(int(1 == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d85c6-2a40-45a5-8bc4-bffa3197ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "str1 = 'H47436-2|R06Z'\n",
    "str2 = 'H47436-4|R04Z'\n",
    "\n",
    "# Вычисление расстояния Левенштейна\n",
    "distance = Levenshtein.distance(str1, str2)\n",
    "print(f\"Расстояние Левенштейна: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd277b-338b-4126-8f88-bdc8bc537bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'a': 'asdfasdf', 'b': 2, 'c': 3}\n",
    "# Удаление ключа 'b'\n",
    "del my_dict['b']\n",
    "\n",
    "print(f\"Обновлённый словарь: {my_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75713398-3c04-4142-8a44-6f3c72493472",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_dict['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a5a0d-8abc-4c71-9ac0-9ac9a4c6a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Слово, которое нужно найти\n",
    "word_to_find = 'слово'\n",
    "\n",
    "# Пример строки\n",
    "text = \"Это тестовое слово в середине слово строки, и ещё одно слово в конце.\"\n",
    "\n",
    "# Регулярное выражение для поиска слова\n",
    "pattern = rf'\\b{word_to_find}\\b'\n",
    "\n",
    "# Поиск совпадений\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Найденные совпадения: {matches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e649612-0382-4846-8f1a-2a5ef72c5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if matching_keys:\n",
    "    print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ad9be-3426-436e-9bb3-8aa542a49840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример двух словарей\n",
    "attr_1 = {'a': 1, 'b': 2, 'c': 3}\n",
    "attr_2 = {'b': 4, 'c': 5, 'd': 6}\n",
    "\n",
    "# Находим общие ключи\n",
    "attr_1_and_2 = attr_1.keys() & attr_2.keys()\n",
    "print(\"Общие ключи:\", attr_1_and_2)\n",
    "\n",
    "# Шаблон для поиска и удаления ключа\n",
    "key_to_remove = 'b'\n",
    "\n",
    "# Проверяем, есть ли ключ в общих ключах, и удаляем его, если есть\n",
    "if key_to_remove in attr_1_and_2:\n",
    "    print(f\"Ключ '{key_to_remove}' найден в общих ключах и будет удален\")\n",
    "    attr_1_and_2.remove(key_to_remove)\n",
    "\n",
    "print(\"Оставшиеся общие ключи:\", attr_1_and_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c46221-747a-4867-91b0-bed21e2f5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Пример списков\n",
    "exact_attributes = ['attr1', 'attr2', 'attr_special', 'some_other_attr', 'another_special_attr']\n",
    "pattern_attributes = [r'.*_special$', r'^attr\\d$']\n",
    "\n",
    "# Фильтрация списка exact_attributes\n",
    "filtered_attributes = [\n",
    "    attr for attr in exact_attributes\n",
    "    if not any(re.match(pattern, attr) for pattern in pattern_attributes)\n",
    "]\n",
    "\n",
    "print(\"Отфильтрованный список:\", filtered_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d39363-25ff-43ce-8e3f-b2457337b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exact_attributes.txt', 'r', encoding='utf-8') as file:\n",
    "        exact_attributes = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816f0bf-7859-4ac1-9cfb-77aa19e56abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exact_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a395df-92b8-4dcd-adcd-483b195104c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_attributes[499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88881bfa-e256-4ddd-886c-99573368b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from baseline import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff41fd-8232-4353-a2b1-68ab19b5bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "val_features = joblib.load('./data/val_features.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632f4d3-abb9-409f-bf27-fd4d90ecbfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614973c7-30ff-4fbf-a93e-ff0b97471ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Пример плотной матрицы NumPy\n",
    "# Преобразование плотной матрицы в разреженную матрицу формата CSR (Compressed Sparse Row)\n",
    "sparse_matrix = sparse.csr_matrix(val_features)\n",
    "\n",
    "# Проверяем размер занимаемой памяти\n",
    "print(f\"Размер плотной матрицы: {val_features.nbytes} байт\")\n",
    "print(f\"Размер разреженной матрицы: {sparse_matrix.data.nbytes + sparse_matrix.indptr.nbytes + sparse_matrix.indices.nbytes} байт\")\n",
    "\n",
    "# Если нужно преобразовать обратно в плотную матрицу\n",
    "dense_matrix_back = sparse_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b4db2-a1c2-4589-bc57-690b4e3d8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(sparse_matrix, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927cc80a-6946-46dd-a23a-2ba99cda8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9f590-b363-4e99-89e1-e95bbd6ad0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd312e0-e6fd-4738-a35c-d3d9369a5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "print(catboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d3192-a82e-4f99-83bc-ec984fb8d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Предположим, что sparse_matrix уже создана и является разреженной матрицей формата CSR\n",
    "sparse_matrix = sparse.csr_matrix(val_features)\n",
    "\n",
    "# Разбиваем разреженную матрицу на тренировочную и тестовую выборки\n",
    "train_data, val_data = train_test_split(sparse_matrix, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Обратите внимание, что если вы работаете с разреженными матрицами, `train_test_split` вернет их в разреженном формате\n",
    "print(f\"Тип train_data: {type(train_data)}\")\n",
    "print(f\"Тип val_data: {type(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223bec9-6882-4555-b931-7b47096a969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = joblib.load('./data/X_train.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd9016-3d1b-474f-842d-b98ef7fb6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d519dbc-067b-46c5-bf91-f7d953356229",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = joblib.load('./data/train_data.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d1190-7788-45a5-9bc4-c0b5b19a3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaba6e2-2770-4fc7-a9de-5ab21ee9a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_path = './data/train/train.parquet'\n",
    "train = pd.read_parquet(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c250b7-94bf-4c46-a9cc-eed38f37b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910c504-cbda-444a-a354-bcf6eaf41f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a867ea-1816-4c06-9907-b552501b5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_array = X_train[0].toarray()\n",
    "print(dense_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eeb510-068c-4cc5-9f87-7c5d329cb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce232f-b785-4a05-85d4-6a33a6563db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Преобразуем первую строку в плотный массив (dense array)\n",
    "dense_array = X_train[0].toarray()\n",
    "\n",
    "# Получаем индексы ненулевых элементов\n",
    "nonzero_indices = dense_array.nonzero()\n",
    "\n",
    "# Печатаем ненулевые элементы и их индексы\n",
    "for index in zip(nonzero_indices[1], dense_array[0, nonzero_indices[1]]):\n",
    "    print(f\"Index: {index[0]}, Value: {index[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e7340-fa58-4f98-ae60-84c08636b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Пример генерации разреженных данных\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Генерация случайных разреженных данных\n",
    "n_samples = 1000000\n",
    "n_features = 10000\n",
    "X_sparse = csr_matrix(np.random.binomial(1, 0.01, size=(n_samples, n_features)))\n",
    "y = np.random.randint(0, 2, size=n_samples)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sparse, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Настройка гиперпараметров LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'goss',  # Gradient-based One-Side Sampling, работает лучше на разреженных данных\n",
    "    'objective': 'binary',  # Двухклассовая классификация\n",
    "    'metric': 'binary_logloss',  # Логарифмическая потеря\n",
    "    'num_leaves': 64,  # Количество листьев в каждом дереве\n",
    "    'max_depth': -1,  # Без ограничения глубины\n",
    "    'learning_rate': 0.05,  # Скорость обучения\n",
    "    'feature_fraction': 0.7,  # Доля признаков, используемых при построении каждого дерева\n",
    "    'bagging_fraction': 0.8,  # Доля данных для бэггинга\n",
    "    'bagging_freq': 5,  # Частота бэггинга\n",
    "    'min_data_in_leaf': 50,  # Минимальное количество данных в листе\n",
    "    'lambda_l1': 0.1,  # L1-регуляризация\n",
    "    'lambda_l2': 0.1,  # L2-регуляризация\n",
    "    'max_bin': 255,  # Максимальное количество бинов для разбиения\n",
    "    'verbose': -1  # Отключить вывод информации о процессе обучения\n",
    "}\n",
    "\n",
    "# Подготовка данных для LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Обучение модели\n",
    "model = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[test_data], early_stopping_rounds=50)\n",
    "\n",
    "# Прогнозирование и оценка точности\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edef75-40eb-48c8-9739-aeecfc25f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Диаметр, мм': (['0.28'], ['0.28'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea7214-aaa3-4b6c-be0a-aef46b504de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Диаметр, мм': ['0.28', '0.29']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253fc13-156a-40b3-85e6-2e64e374e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dict1['Диаметр, мм'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e15681-cec1-47ae-9bcb-8e36e85926f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(dict1['Диаметр, мм'], list):\n",
    "    out = ' '.join(map(str, dict1['Диаметр, мм']))\n",
    "else:\n",
    "    out = str(dict1['Диаметр, мм'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da777dfc-9802-42d3-b648-aff73bc0f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9beae1-05af-4488-bc22-3e2d2430e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_text = ' '.join(\n",
    "            [' '.join(map(str, v)) if isinstance(v, list) else str(v) for v in dict1['Диаметр, мм']]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa0c0b-ab35-468d-9beb-d70840f6a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(attributes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab29e1-13ae-468f-abcb-d472f1fdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e425d6a-3bf9-45e7-8431-8f891c3a1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map(str, dict1['Диаметр, мм'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63850be5-0a31-4174-8252-14e68ef02e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(map(str, ['0.28', '0.28']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15308cb8-bf50-4a7a-80bf-e87862974d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_texts_similarity(text1, text2):\n",
    "        '''\n",
    "        Возвращает сходство между текстами text1 и text2\n",
    "        '''\n",
    "        # Создание экземпляра TfidfVectorizer\n",
    "        tfidf_vectorizer = TfidfVectorizer(\n",
    "            token_pattern=r'\\b\\w+\\b',  # Учитывать любые слова, включая цифры\n",
    "            stop_words=None  # Не использовать встроенные стоп-слова\n",
    "        )\n",
    "        # Преобразование текстов в TF-IDF векторы\n",
    "        # print('text1:', text1, 'text2:', text2)\n",
    "        match1 = re.search(r'^\\d+$', text1)\n",
    "        match2 = re.search(r'^\\d+$', text2)\n",
    "        if match1 and match2:\n",
    "            # Если это числа возвращаем соотношение\n",
    "            match1 = int(match1.group())\n",
    "            match2 = int(match2.group())\n",
    "            return(min(match1,match2)/max(match1,match2))\n",
    "        else:\n",
    "            try:\n",
    "                tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
    "                return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "            except ValueError as e:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccc997-6efb-4baa-93ee-e1ab4ded1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_texts_similarity('100', '99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ca202-7bd9-48c6-8249-db0e5f837f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "match1 = 0\n",
    "match2 = 0\n",
    "if max(match1,match2) != 0:\n",
    "    a = (min(match1,match2)/max(match1,match2))\n",
    "else:\n",
    "    a =0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1597f-d16d-4b1c-bb13-d64d57d44cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "train_data = joblib.load('./data/val_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bc9c6-0200-4f7d-954e-540511650ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "categories_list = [[] for _ in range(4)]\n",
    "for i, (index, row) in enumerate(tqdm(train_data.iterrows(), total=len(train_data), desc=\"Processing rows\", ncols=100, leave=True)):\n",
    "    for j in range(1,5):\n",
    "        categories_list[j-1].append(str(row[f'categories_1'][f'{j}']))\n",
    "        categories_list[j-1].append(str(row[f'categories_2'][f'{j}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7eeb3-0e1b-44b9-920c-c258bbf56c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#for i in range(4):\n",
    "for i in range(2):\n",
    "    print(f\"*************** Заголовок {i} ******************\")\n",
    "    # Слова и их индексы\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=6000)\n",
    "    tfidf_vectorizer.fit(categories_list[i])\n",
    "    print(\"Длина словаря:\", len(tfidf_vectorizer.vocabulary_))\n",
    "    print(\"Словарь (vocabulary):\")\n",
    "    print(tfidf_vectorizer.vocabulary_)\n",
    "    # IDF значения для каждого слова\n",
    "    print(\"\\nIDF значения для слов:\")\n",
    "    print(dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328fb4f-17c6-4ece-b6da-aa6f79814b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!\n",
    "from scipy.sparse import lil_matrix, hstack, csr_matrix\n",
    "at = csr_matrix(tfidf_vectorizer.transform(['спорт товары']).toarray())\n",
    "at[at > 0] = 1\n",
    "at[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3bbdb-0e6d-4b10-97ff-62e15f5ab29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(at.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca85727-b9d6-4594-b2ac-75c4285dbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[0]['categories_1']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc28ba-6c38-4e41-8aa2-9bca46067a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[0]['categories_1']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba5ea4-ff12-471e-bae9-471cdbd4efbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0b817-4749-4bc8-9d51-fb6fbc233c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import make_exact_attributes_from_train\n",
    "make_exact_attributes_from_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a5438-7ed2-4b8d-876a-8cf5857f4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import load_features\n",
    "X_train, X_val, y_train, y_val = load_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f84ad-e9f1-43c6-8bcd-078929e988f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b90dca-6936-4696-b251-029c6c51a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a728c-ea3b-4f71-b80e-dee0cc5c83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # Определяем параметры модели\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        #'metric': 'binary_logloss',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 255),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10)\n",
    "    }\n",
    "\n",
    "\n",
    "    # Обучаем модель\n",
    "    model = LGBMClassifier(**params)\n",
    "    # model.fit(X_train, y_train, \n",
    "    #           eval_set=[(X_val, y_val)],\n",
    "    #           early_stopping_rounds=50, \n",
    "    #           verbose=False,\n",
    "    #           callbacks=[LightGBMPruningCallback(trial, 'binary_logloss')])\n",
    "\n",
    "    # model.fit(X_train, y_train, verbose=False)\n",
    "    # model.fit(X_train, y_train, \n",
    "    #           callbacks=[lgb.early_stopping(stopping_rounds=50),])\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=1000,\n",
    "                      valid_sets=[val_data],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50),]\n",
    "                     )\n",
    "    # Получаем прогнозы\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_pred_prob)\n",
    "    prauc = auc(recall, precision)\n",
    "\n",
    "    return prauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf26e6d-7d45-446c-8cb7-7bebd51999fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcb967-690c-4875-954e-ee4cfd2b5b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=800)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12d3db-1424-4c50-ae3b-00d70d395db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "val_features = joblib.load('./data/val_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcce909-c4be-4ab6-9cd9-3baddbd1d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03b567-09a1-4475-9b12-bc198dae96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = joblib.load('./data/result_data.pkl')\n",
    "result_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c171f-9be4-4f05-ac2a-765cd5ba7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a359941-c679-4725-8ff2-4fd51e265b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features1 = val_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b876f-e73d-42a0-b717-cc91b906dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f5f77-bf52-47b5-b34d-31cd42e74c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest(value, targets=[0.1, 0.2, 0.6, 0.8, 0.9, 0.95, 0.97, 1]):\n",
    "    return min(targets, key=lambda x: abs(x - value))\n",
    "\n",
    "# Пример использования\n",
    "number = 0.99\n",
    "rounded_number = round_to_nearest(number)\n",
    "print(rounded_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc046e-6b31-4276-b726-e5e8821e571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_words(text):\n",
    "    # Ищем слова длиной 5 и более символов, содержащие не менее трех цифр\n",
    "    pattern = r'\\b\\w{5,}\\b'  # ищем слова длиной 5 и более символов\n",
    "    words = re.findall(pattern, text)\n",
    "    \n",
    "    # Фильтруем слова, чтобы оставить только те, в которых не менее трех цифр\n",
    "    result = [word for word in words if len(re.findall(r'\\d', word)) >= 3]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Пример использования\n",
    "text = \"There are some words like 123abc, xyz789, and 12a3b4c which should be found.\"\n",
    "filtered_words = extract_words(text)\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c8d9e-d19e-4280-b704-1b0a25320dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_words(list1, list2):\n",
    "    # Преобразуем списки в множества и находим пересечение\n",
    "    common_words = set(list1) & set(list2)\n",
    "    return list(common_words)\n",
    "\n",
    "# Пример использования\n",
    "list1 = [\"apple123\", \"banana456\", \"grape7891\"]\n",
    "list2 = [\"banana456\", \"orange123\", \"grape789\", \"melon234\"]\n",
    "\n",
    "common_words = find_common_words(list1, list2)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a46d1e-96ed-4fd1-998b-5fdbab83e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(common_words) > 0:\n",
    "    print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7a0e3-7dcb-4f3e-a0cd-8af6b9b95fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    # Ищем слова длиной 5 и более символов, содержащие не менее трех цифр\n",
    "    # pattern = r'\\b\\w{5,}\\b'  # ищем слова длиной 5 и более символов\n",
    "    # 1. \\b\\w{3,}\\b - слова длиной не менее 3 символов с цифрами или английскими буквами\n",
    "    # 2. \\b\\d{7,}\\b - слова, состоящие только из цифр, длиной не менее 7 символо\n",
    "    #pattern = r'\\b(?:(?:[A-Z]\\d|\\d[A-Z])|\\d{7,})\\b'\n",
    "\n",
    "    # Исходный текст    \n",
    "    # Удаляем слова лишние\n",
    "    text = re.sub(r'\\модель\\b|\\bеще что удалить\\b', '', text)\n",
    "    \n",
    "    #pattern = r'\\b(?:(?:[A-ZА-Я\\d\\s\\-]*?(?:[A-ZА-Я]\\d|[A-ZА-Я]{3,})|(?:\\d[A-ZА-Я]|[A-ZА-Я]{3,})[А-ЯA-Z\\d\\s\\-]*?)|\\d{7,})\\b'\n",
    "    #pattern = r'\\b(?:(?:[A-ZА-Я\\d]*?[A-ZА-Я]\\d|\\d[A-ZА-Я][A-ZА-Я\\d]*?)|\\d{7,})\\b'\n",
    "    pattern = r'\\b([А-ЯA-Z\\d\\s\\-\\/]+)\\b'\n",
    "    #words = re.findall(pattern, text)\n",
    "    words = re.findall(pattern, text)\n",
    "    \n",
    "    # Фильтруем слова, чтобы оставить только те, в которых не менее трех цифр\n",
    "    #result = [re.sub(r'[\\s+\\-]', ' ', word).strip() for word in words if len(word) >= 7]\n",
    "    result = [re.sub(r'[\\s\\-]+', ' ', word).strip() for word in words if len(word.strip()) >= 7]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def find_common_words(list1, list2):\n",
    "    # Преобразуем списки в множества и находим пересечение\n",
    "    common_words = set(list1) & set(list2)\n",
    "    return list(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1227c3cc-220e-4f40-a100-5153bdd29423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_1 = '2шт роликовая щетка для пылесоса Pro FC6 XC8 XC7:'\n",
    "# name_2 = '2 шт. роликовая щетка, совместимая с пылесосом Pro FC6 XC8 XC7'\n",
    "name_1 = 'Сплит-система AUX ASW-H12B4/FJ-SR1 AS-H12B4/FJ-R1 Серия FJ предназначена для помещения площадью 35-40 кв.метров. Этот кондиционер способен охладить/обогреть небольшое офисное помещение или квартиру из одной/двух комнат, общей площадью не более 35-40 м2. Прекрасно подойдет для просторной гостиной, а также небольшого коммерческого помещения.***Технические характеристики и внешний вид оборудования, приведенного в данном каталоге, могут быть изменены производителем без предварительного уведомления.:'\n",
    "name_2 = 'Сплит-система AUX ASW-H18B4/FJ-SR1 AS-H18B4/FJ-R1 Серия FJ предназначена для помещения площадью до 50 кв.метров. Сплит-системы этой мощности нашли широкое применение в частных домах, многокомнатных квартирах, коммерческих объектах. Не рекомендуется устанавливать в спальных комнатах. Это хороший и производительный кондиционер, который способен как охлаждать, так и обогревать достаточно объемные помещения.***Технические характеристики и внешний вид оборудования, приведенного в данном каталоге, могут быть изменены производителем без предварительного уведомления.:'\n",
    "list_1 = extract_words(name_1)\n",
    "list_2 = extract_words(name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f91b53-7e72-416c-b87a-2d1c64b6e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7ec91-f9d9-4228-ab81-5e1e28dc9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e69f1-8c65-400d-a40b-5b4696df3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.search(r'указан.{,7}упаковк', 'указан на упаковке товара'):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda5314-5175-4ace-8d95-83a99c078d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'указан.{,7}упаковк'\n",
    "text_1 = 'Состав: полный состав указан на упаковке товара'\n",
    "text_2 = 'Состав: полный состав указан на упаковке товара'\n",
    "if ((re.search(pattern, text_1) and (len(text_1) < 100)) or\n",
    "    (re.search(pattern, text_2) and (len(text_2) < 100))):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c1436-f88c-4e18-9df4-c94c4ffe86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((re.search(pattern, text_1)) or\n",
    "    (re.search(pattern, text_2))):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48996aa-e693-47f4-90db-18a7969c8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf625612-7ed3-41ad-bf14-837ee732a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходная строка на русском\n",
    "my_string = \"пример\"\n",
    "\n",
    "# Получение длины строки в символах\n",
    "length = len(my_string)\n",
    "\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78143f30-8361-495f-8b1e-6f05172fdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import load_features\n",
    "#X_train,  y_train, X_val, y_val = load_features()\n",
    "X_train, X_val, y_train, y_val = load_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286da407-d2b0-441b-aa00-2e2f0c362a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f9eae-2ffb-40a3-83b7-33240b6e53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e169252-8fa9-4744-95d4-cef9dc1f5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import adjust_class_balance\n",
    "X_train, y_train = adjust_class_balance(X_train, y_train, remove_fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72d7e5-3659-4741-b97c-e808bc9a61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import adjust_class_balance\n",
    "X_balanced, y_balanced = adjust_class_balance(X_val, y_val, remove_fraction=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6769b-0927-43e0-8ce0-535e046cbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Предположим, что y_val - это массив меток классов\n",
    "class_balance = Counter(y_val)\n",
    "print(\"Баланс классов:\", class_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a827d25-5ff2-4260-a7e3-6f585a081331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предположим, что y_val - это массив меток классов\n",
    "class_balance = Counter(y_balanced)\n",
    "print(\"Баланс классов:\", class_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b3e30-f79d-4292-a05b-c670f000f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предположим, что y_val - это массив меток классов\n",
    "class_balance = Counter(y_balanced)\n",
    "print(\"Баланс классов:\", class_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc02b66-cdea-41f5-8909-7b4119895623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def adjust_class_balance(X, y, remove_fraction):\n",
    "    \"\"\"\n",
    "    Удаляет определенную долю строк с меткой 1, чтобы изменить баланс классов.\n",
    "    \n",
    "    :param X: разряженная матрица признаков (csr_matrix)\n",
    "    :param y: метки классов (numpy array)\n",
    "    :param remove_fraction: доля строк с меткой 1, которую нужно удалить (значение от 0 до 1)\n",
    "    :return: измененные X и y\n",
    "    \"\"\"\n",
    "    # Находим индексы строк с меткой 1\n",
    "    indices_one = np.where(y == 0)[0]\n",
    "    \n",
    "    # Определяем количество строк, которые нужно удалить\n",
    "    num_to_remove = int(len(indices_one) * remove_fraction)\n",
    "    \n",
    "    # Случайным образом выбираем строки для удаления\n",
    "    np.random.seed(42)  # для воспроизводимости\n",
    "    indices_to_remove = np.random.choice(indices_one, num_to_remove, replace=False)\n",
    "    \n",
    "    # Удаляем выбранные строки из X и y\n",
    "    mask = np.ones(len(y), dtype=bool)\n",
    "    mask[indices_to_remove] = False\n",
    "    \n",
    "    X_balanced = X[mask]\n",
    "    y_balanced = y[mask]\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "# Пример использования\n",
    "# X_va - разряженная матрица признаков (csr_matrix)\n",
    "# y_val - метки классов (numpy array)\n",
    "\n",
    "# Удаляем 30% строк с меткой 1\n",
    "X_balanced, y_balanced = adjust_class_balance(X_val, y_val, remove_fraction=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe8550-5ee7-43a4-a070-20180b3c706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdf5bd-3326-4bb7-a790-051badee2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from baseline import make_report\n",
    "make_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd528a51-e201-4961-a01e-7eca87d32712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
